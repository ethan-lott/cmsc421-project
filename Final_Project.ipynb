{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MelBkPJN9Ly8",
        "outputId": "3163a23b-ada1-40c4-aaf5-02bf83c1eb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (0.29.1)\n",
            "Requirement already satisfied: pyvirtualdisplay in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (3.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from gymnasium) (1.26.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from gymnasium) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from gymnasium) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from gymnasium) (0.0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pygame in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (2.5.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: opencv-python in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from opencv-python) (1.26.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (3.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.21 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ethan\\anaconda3\\envs\\ml\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary packages\n",
        "%pip install gymnasium pyvirtualdisplay\n",
        "%pip install pygame\n",
        "%pip install opencv-python\n",
        "%pip install -U matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WuHV7MWr-BvY"
      },
      "outputs": [],
      "source": [
        "## Import modules\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pygame\n",
        "import random\n",
        "import itertools\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jNJ41vrJLhUh"
      },
      "outputs": [],
      "source": [
        "## Define helper functions\n",
        "\n",
        "def color(val, max):\n",
        "    if val > 0:\n",
        "      return (int(255*(1-val/max)),255,int(255*(1-val/max)))\n",
        "    elif val == 0:\n",
        "      return (255,255,255)\n",
        "    else:\n",
        "      return (255,int(255*(1+val/max)),int(255*(1+val/max)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bGBavUv0-EOR"
      },
      "outputs": [],
      "source": [
        "## Define environment class\n",
        "\n",
        "class ParkingLot(gym.Env):\n",
        "\n",
        "  def __init__(self, num_lanes, spots_per_lane, amt_full = 0.5):\n",
        "\n",
        "    self.width = num_lanes * 3 + 1\n",
        "    self.height = spots_per_lane + 2\n",
        "\n",
        "    self.observation_space = spaces.Box(low=np.array([0, 0, 0]), high=np.array([self.height-1, self.width-1, 3]), shape=(3,), dtype=np.int32) # {y, x, direction (R,D,L,U)}\n",
        "    self.action_space = spaces.Discrete(3) # {Go forward, turn right, turn left}\n",
        "\n",
        "    self.agent_state = np.array([0,0,0])\n",
        "    self.grid = np.zeros((self.height, self.width))\n",
        "\n",
        "    # Adjust rewards by location\n",
        "    for l in range(1, num_lanes+1):\n",
        "      self.grid[1:spots_per_lane+1, l*3-2] = 2*l-1\n",
        "      self.grid[1:spots_per_lane+1, l*3-1] = 2*l\n",
        "\n",
        "    self.lane_idx = np.array([l*3+1 for l in range(num_lanes)] + [l*3+2 for l in range(num_lanes)])\n",
        "    for s in range(spots_per_lane):\n",
        "      self.grid[s+1, self.lane_idx] += s\n",
        "    self.grid = np.square(self.grid)\n",
        "\n",
        "    # Add cars\n",
        "    self.r_max = np.max(self.grid)\n",
        "    p = (0.5+amt_full) * self.grid / self.r_max\n",
        "\n",
        "    for l in range(1, num_lanes+1):\n",
        "      for s in range(spots_per_lane):\n",
        "        if random.random() < p[s+1, l*3-2]:\n",
        "          self.grid[s+1, l*3-2] = -self.r_max\n",
        "        if random.random() < p[s+1, l*3-1]:\n",
        "          self.grid[s+1, l*3-1] = -self.r_max\n",
        "\n",
        "  def __get_obs(self):\n",
        "    return self.agent_state\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    super().reset(seed=seed)\n",
        "    self.agent_state = np.array([0,0,0])\n",
        "    observation = self.__get_obs()\n",
        "    info = None\n",
        "    return observation, info\n",
        "\n",
        "  def compute_reward(self, observation):\n",
        "    if ((not (observation[0] in np.arange(self.height) and observation[1] in np.arange(self.width))) or \n",
        "        ((not observation[1] % 3 == 0) and ((observation[0] == 1 and observation[2] == 1) or (observation[0] == self.height - 2 and observation[2] == 3)))):\n",
        "      return -self.r_max\n",
        "    else:\n",
        "      return self.grid[observation[0], observation[1]]\n",
        "\n",
        "  def step(self, action):\n",
        "\n",
        "      dir = self.agent_state[2]\n",
        "      if action == 0:\n",
        "        self.agent_state[0 if dir%2==1 else 1] += -1 if dir//2==1 else 1\n",
        "      elif action == 1:\n",
        "        self.agent_state[2] = (dir + 1) % 4\n",
        "      elif action == 2:\n",
        "        self.agent_state[2] = (dir - 1) % 4\n",
        "\n",
        "      observation = self.__get_obs()\n",
        "      reward = self.compute_reward(observation)\n",
        "      terminated = reward != 0\n",
        "\n",
        "      return observation, reward, terminated, False, None\n",
        "\n",
        "  def _render_frame(self, screen, window_width, window_height):\n",
        "    w = window_width/self.width\n",
        "    h = window_height/self.height\n",
        "    for r in range(self.height):\n",
        "      for c in range(self.width):\n",
        "        pygame.draw.rect(screen, color(self.grid[r, c], np.max(np.abs(self.grid))), pygame.Rect(c*w, r*h, w, h))\n",
        "\n",
        "        #for adding lines\n",
        "        #vertical lines through the middle of the 2 spots\n",
        "        if c % 3 == 2 and r != 0 and r != self.height-1:\n",
        "          pygame.draw.line(screen, (0,0,0), (c*w,r*h),((c*w,(r+1)*h)))\n",
        "\n",
        "        #for the horizontal lines through the spot\n",
        "        if c % 3 != 0 and r != 0 and r != self.height:\n",
        "          pygame.draw.line(screen, (0,0,0), (c*w,r*h),(((c+1)*w,r*h)))\n",
        "\n",
        "\n",
        "\n",
        "    pygame.draw.polygon(screen, 'blue', self.coordinates(w, h))\n",
        "\n",
        "  def render(self, screen, window_width, window_height):\n",
        "    return self._render_frame(screen, window_width, window_height)\n",
        "\n",
        "  def coordinates(self, w, h):\n",
        "    if self.agent_state[2] == 0:\n",
        "      return [\n",
        "        (self.agent_state[1]*w+w//4, self.agent_state[0]*h+h//4),\n",
        "        (self.agent_state[1]*w+3*w//4, self.agent_state[0]*h+h//2),\n",
        "        (self.agent_state[1]*w+w//4, self.agent_state[0]*h+3*h//4)]\n",
        "    elif self.agent_state[2] == 1:\n",
        "      return [\n",
        "        (self.agent_state[1]*w+w//4, self.agent_state[0]*h+h//4),\n",
        "        (self.agent_state[1]*w+w//2, self.agent_state[0]*h+3*h//4),\n",
        "        (self.agent_state[1]*w+3*w//4, self.agent_state[0]*h+h//4)]\n",
        "    elif self.agent_state[2] == 2:\n",
        "      return [\n",
        "        (self.agent_state[1]*w+w//4, self.agent_state[0]*h+h//2),\n",
        "        (self.agent_state[1]*w+3*w//4, self.agent_state[0]*h+h//4),\n",
        "        (self.agent_state[1]*w+3*w//4, self.agent_state[0]*h+3*h//4)]\n",
        "    elif self.agent_state[2] == 3:\n",
        "      return [\n",
        "        (self.agent_state[1]*w+w//2, self.agent_state[0]*h+h//4),\n",
        "        (self.agent_state[1]*w+w//4, self.agent_state[0]*h+3*h//4),\n",
        "        (self.agent_state[1]*w+3*w//4, self.agent_state[0]*h+3*h//4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "IwSyeeCfc_I4"
      },
      "outputs": [],
      "source": [
        "## Implement Q-learning\n",
        "\n",
        "class QLearning():\n",
        "  def __init__(self, env, exploration, gamma, alpha, obs_space_n, action_space_n):\n",
        "    self.env = env\n",
        "    self.exploration = exploration\n",
        "    self.gamma = gamma\n",
        "    self.alpha = alpha\n",
        "    self.q_table = np.zeros((obs_space_n, action_space_n))\n",
        "\n",
        "  def sample_action(self, observation):\n",
        "    r = random.random()\n",
        "    if r < self.exploration:\n",
        "      action = self.env.action_space.sample()\n",
        "    else:\n",
        "      action = np.argmax(self.q_table[observation])\n",
        "    return action\n",
        "\n",
        "  def update_table(self, observation, action, reward, new_observation, terminated):\n",
        "    old_q = self.q_table[observation, action]\n",
        "    if new_observation >= 0 and new_observation < self.q_table.shape[0]:\n",
        "      sample = reward + self.gamma * np.max(np.delete(self.q_table[new_observation], action))\n",
        "    else:\n",
        "      sample = reward + self.gamma * -1\n",
        "    new_q = (1 - self.alpha) * old_q + self.alpha * sample\n",
        "    self.q_table[observation, action] = new_q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Generate parking lot and Q-Learner\n",
        "\n",
        "## Generate parking lot and Q-Learner\n",
        "import matplotlib.pyplot as plt\n",
        "lot = ParkingLot(\n",
        "  num_lanes=3,\n",
        "  spots_per_lane=6,\n",
        "  amt_full=0.6)\n",
        "\n",
        "q_learning = QLearning(\n",
        "  env=lot,\n",
        "  exploration=0.3,\n",
        "  gamma=0.99,\n",
        "  alpha=0.9,\n",
        "  obs_space_n=np.product(lot.observation_space.high+1),\n",
        "  action_space_n=lot.action_space.n)\n",
        "\n",
        "grid_L = 40\n",
        "window_width = lot.width * grid_L\n",
        "window_height = lot.height * grid_L\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((window_width, window_height))\n",
        "lot.render(screen, window_width, window_height)\n",
        "view = pygame.surfarray.array3d(screen).transpose([1, 0, 2])\n",
        "pygame.quit()\n",
        "\n",
        "plt.imshow(view)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [01:27<00:00, 1363.79it/s]\n"
          ]
        }
      ],
      "source": [
        "## Train agent\n",
        "import tqdm\n",
        "\n",
        "n = lot.width * lot.height * 1500\n",
        "\n",
        "for i in tqdm.tqdm(range(n)):\n",
        "  terminated = False\n",
        "  lot.reset()\n",
        "  while not terminated:\n",
        "    s = lot.agent_state.copy()\n",
        "    s_ind = (s[0] * lot.width + s[1]) * 4 + s[2]\n",
        "    a = q_learning.sample_action(s_ind)\n",
        "    s1, R, terminated, truncated, info = lot.step(a)\n",
        "    s1_ind = (s1[0] * lot.width + s1[1]) * 4 + s1[2]\n",
        "    q_learning.update_table(s_ind, a, R, s1_ind, terminated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Test agent\n",
        "\n",
        "RENDER_STEP_DELAY = 200 # set to ms time if you want it to run automatically, 0 if you want to see each frame\n",
        "grid_L = 40\n",
        "window_width = lot.width * grid_L\n",
        "window_height = lot.height * grid_L\n",
        "pygame.init()\n",
        "screen = pygame.display.set_mode((window_width, window_height))\n",
        "\n",
        "q_learning.exploration = 0.0\n",
        "observation, info = lot.reset()\n",
        "terminated = False\n",
        "lot.render(screen, window_width, window_height)\n",
        "img_bgr = cv2.cvtColor(pygame.surfarray.array3d(screen).transpose([1, 0, 2]), cv2.COLOR_RGB2BGR)\n",
        "cv2.imshow(\"Parking Lot Simulator\", img_bgr)\n",
        "cv2.waitKey(RENDER_STEP_DELAY)\n",
        "clear_output()\n",
        "\n",
        "while not terminated:\n",
        "    action = q_learning.sample_action((observation[0] * lot.width + observation[1]) * 4 + observation[2])\n",
        "    observation, reward, terminated, truncated, info = lot.step(action)\n",
        "    lot.render(screen, window_width, window_height)\n",
        "    view = pygame.surfarray.array3d(screen)\n",
        "    view = view.transpose([1, 0, 2])\n",
        "    img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imshow(\"Parking Lot Simulator\", img_bgr)\n",
        "    cv2.waitKey(RENDER_STEP_DELAY)\n",
        "\n",
        "cv2.waitKey(0) # holds the last frame till you hit a key\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(0) # needed for the destroyallwindows event to be handled\n",
        "\n",
        "pygame.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
